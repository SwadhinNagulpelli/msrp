{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snnOaSAzxsar",
        "outputId": "593ab85e-0c5b-4f62-ed6b-c70b5b2beb99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data(path):\n",
        "  return pd.read_csv(path, sep = '\\t', quoting=csv.QUOTE_NONE) "
      ],
      "metadata": {
        "id": "lNkjxGvG6WYn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_bal(path_train, path_test):\n",
        "  df = extract_data(path_train)\n",
        "  dft = extract_data(path_test)\n",
        "\n",
        "  df_full = df.append(dft)\n",
        "\n",
        "  data_1 = df_full[df_full['Quality']==1]\n",
        "  data_2 = df_full[df_full['Quality']==0]\n",
        "\n",
        "  df_bal = data_2.append(data_1[:1900])\n",
        "\n",
        "  df_bal = df_bal.sample(frac = 1)\n",
        "  df_bal[\"merge\"] = df_bal[[\"#1 String\", \"#2 String\"]].apply(\"-\".join, axis=1)\n",
        "  df_bal.reset_index(inplace=True)\n",
        "\n",
        "  return df_bal\n"
      ],
      "metadata": {
        "id": "LMAdadedx7S0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preproc(data_col):\n",
        "  import re\n",
        "\n",
        "  lemm = WordNetLemmatizer()\n",
        "  corpus = []\n",
        "  for i in range(len(data_col)):\n",
        "    review = re.sub(\"[^a-zA-Z0-9]\",\" \",data_col[i]).lower().split()\n",
        "    review = [lemm.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
        "    corpus.append(\" \".join(review))\n",
        "  return corpus\n"
      ],
      "metadata": {
        "id": "zx9tIOnQyCwo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cv_data(df_bal):\n",
        "  string_merge = preproc(df_bal['merge'])\n",
        "\n",
        "  cv = CountVectorizer(max_features=2500,binary=True)\n",
        "  X = cv.fit_transform(string_merge).toarray()\n",
        "  y = df_bal['Quality']\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.15, random_state=42)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test\n",
        "    \n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "rqWAN4yMyDVy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_pipe(inp_shape):\n",
        "  input_text = tf.keras.layers.Input(shape=(inp_shape), name='input_text')\n",
        "  dense1 = tf.keras.layers.Dense(256, activation='relu')(input_text)\n",
        "  dropout1 = tf.keras.layers.Dropout(0.3)(dense1)\n",
        "  dense2 = tf.keras.layers.Dense(128, activation='relu')(dropout1)\n",
        "  dropout2 = tf.keras.layers.Dropout(0.3)(dense2)\n",
        "  dense3 = tf.keras.layers.Dense(64, activation='relu')(dropout2)\n",
        "  dropout3 = tf.keras.layers.Dropout(0.3)(dense3)\n",
        "  dense4 = tf.keras.layers.Dense(32, activation='relu')(dropout3)\n",
        "  dropout4 = tf.keras.layers.Dropout(0.3)(dense4)\n",
        "  dense5 = tf.keras.layers.Dense(16, activation='relu')(dropout4)\n",
        "  dropout5 = tf.keras.layers.Dropout(0.3)(dense5)\n",
        "\n",
        "  output = tf.keras.layers.Dense(1, activation='sigmoid')(dropout5)\n",
        "  model_nn = tf.keras.Model(inputs=[input_text], outputs=output)\n",
        "\n",
        "\n",
        "\n",
        "  METRICS = [\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "  ]\n",
        "\n",
        "  model_nn.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=METRICS)\n",
        "\n",
        "  return model_nn"
      ],
      "metadata": {
        "id": "RFbOugCS8SQw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(train_path,test_path,model_save_path):\n",
        "  df_bal = data_bal(train_path, test_path)\n",
        "  X_train, X_test, y_train, y_test = cv_data(df_bal)\n",
        "  model = model_pipe(X_train.shape[1])\n",
        "\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "  history = model.fit(X_train, y_train, epochs=5, batch_size=32,callbacks=[callback],\n",
        "                       validation_split=0.15)\n",
        "  print(X_train.shape)\n",
        "  model.save('model_save_path')\n",
        "\n",
        "  return history,model,X_test,y_test\n"
      ],
      "metadata": {
        "id": "TvfiNG3C8_5-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history,model,X_test,y_test = model_train('/content/drive/MyDrive/msrp_project/MSRParaphraseCorpus/msr_paraphrase_train.txt',\n",
        "                      '/content/drive/MyDrive/msrp_project/MSRParaphraseCorpus/msr_paraphrase_test.txt',\n",
        "                      '/content/drive/MyDrive/msrp_project/MSRParaphraseCorpus/saved_model_nn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_mSAwBX-flz",
        "outputId": "9d232e2c-6da2-49fb-eae4-eb7dcfdb7a2e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-83deef102ae5>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_full = df.append(dft)\n",
            "<ipython-input-3-83deef102ae5>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_bal = data_2.append(data_1[:1900])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "86/86 [==============================] - 8s 13ms/step - loss: 0.6931 - accuracy: 0.4947 - precision: 0.4990 - recall: 0.5390 - val_loss: 0.6890 - val_accuracy: 0.5381 - val_precision: 0.5108 - val_recall: 0.9099\n",
            "Epoch 2/5\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.6665 - accuracy: 0.5876 - precision: 0.5770 - recall: 0.6821 - val_loss: 0.6568 - val_accuracy: 0.5918 - val_precision: 0.5686 - val_recall: 0.6223\n",
            "Epoch 3/5\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.5334 - accuracy: 0.7559 - precision: 0.7629 - recall: 0.7486 - val_loss: 0.7050 - val_accuracy: 0.6041 - val_precision: 0.5851 - val_recall: 0.6052\n",
            "Epoch 4/5\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.3252 - accuracy: 0.8831 - precision: 0.8928 - recall: 0.8728 - val_loss: 0.9003 - val_accuracy: 0.5773 - val_precision: 0.5660 - val_recall: 0.5150\n",
            "Epoch 5/5\n",
            "86/86 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.9512 - precision: 0.9582 - recall: 0.9444 - val_loss: 1.5460 - val_accuracy: 0.5918 - val_precision: 0.5778 - val_recall: 0.5579\n",
            "(3230, 2500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted = y_predicted.flatten()\n",
        "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "\n",
        "print(confusion_matrix(y_test, y_predicted))\n",
        "print(classification_report(y_test, y_predicted)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwHqbDyQGB2D",
        "outputId": "1d1557fc-b450-4006-8981-1b7c8be8b1cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n",
            "[[173 115]\n",
            " [104 179]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.60      0.61       288\n",
            "           1       0.61      0.63      0.62       283\n",
            "\n",
            "    accuracy                           0.62       571\n",
            "   macro avg       0.62      0.62      0.62       571\n",
            "weighted avg       0.62      0.62      0.62       571\n",
            "\n"
          ]
        }
      ]
    }
  ]
}